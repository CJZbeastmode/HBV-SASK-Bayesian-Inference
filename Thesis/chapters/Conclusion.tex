\chapter{Conclusion and Further Outlook} 
In this thesis, the Bayesian inference of hydrological model parameters is implemented. Four versions of Markov chain Monte Carlo algorithms are used for performing Bayesian inference, each delivering different results based on their unique properties. The input algorithm parameter is then specified, in which the accuracy and efficiency metrics of different input algorithm parameters are benchmarked. For some input algorithm parameters, obvious relations between the configurations and the metrics can be found. For others, the configurations do not make a huge difference, or there is a certain configuration that stands out among all the different values of input algorithm parameters.

The first algorithm that is used is the fundamental Metropolis-Hastings, where one sample is generated in each iteration and later on, accepted or rejected based on the calculated acceptance probability using the likelihood function and sampling kernel. Therefore, the sampling kernel and the likelihood kernel play important roles, in which they exert a great impact on the acceptance or rejection.

The other three algorithms that are used all utilize the parallel aspect. The second algorithm, parallel Metropolis-Hastings is the parallel version of the fundamental Metropolis-Hastings algorithm, in which it uses multiple chains for sampling instead of one single chain. The number of chains is, therefore, a relevant factor for the result, since the number of samples generated in each chain is closely related to the convergence rate of the final result.

The third algorithm is the general parallel Metropolis-Hastings algorithm, in which multiple samples are generated in each iteration rather than one single sample. The acceptance probabilities are calculated in the form of a vector, which builds a probability space that allows random sampling to take place. Here, the ratio between the number of samples generated and accepted plays an indispensable role, as discussed in detail in the chapter. Other input algorithm parameters including sampling and likelihood kernels are also relevant, as they contribute to the calculation of the acceptance probability vector. In comparison to the two algorithms above, this algorithm achieves higher accuracy due to the acceptance mechanism, but potentially lower efficiency due to the complexity of acceptance calculation.

The final algorithm is the DREAM algorithm, which improves the sampling phase of the algorithm by adapting the sampling behavior based on past samples and employing a crossover mechanism from differential evolution to efficiently explore the parameter space. Thus, the configurations that are related to crossover, DE (differential evolution), and snooker are relevant for the performance of the result. The DREAM algorithm generally delivers the most accurate and efficient result, achieved not only by running multiple parallel chains but also by enhancing convergence and ensuring thorough exploration of the parameter space.

For the general implementation of Markov chain Monte Carlo algorithms, three other factors are relevant, namely the burn-in phase, the effective sample size, and the initial states. The burn-in phase discards the samples generated at the very start because the Markov chain has not entered the stationary phase yet. The effective sample size allows the algorithm to consider only every n-th sample in the result, allowing less dependency to form between samples in the result that are next to each other. A good choice of initial states optimizes the efficiency of the sampling process by allowing the chains to quickly enter the phase where they sample from the stationary distribution.

For the specific use case for the hydrological model, handling the cases where the samples generated are out of bounds is also crucial. Since the prior parameters are uniformly distributed, the out-of-bounds samples could cause odd behaviors. Using mechanisms such as ignoring, reflection, and aggregation, these cases can be well handled.

Using the algorithms that are mentioned above, the parameters of the HBV-SASK model are inferred, but each to a different extent. While the fundamental and the parallel Metropolis-Hastings algorithms do not give out much information regarding the posterior, the general parallel Metropolis-Hastings and the DREAM algorithms present obvious results, both presented in the thesis. Both algorithms present similar posterior distributions for six of the seven dimensions. This shows the consistency of the inferred results for most cases, indicating the correctness of the inferred results. However, the samples generated by the DREAM algorithms are more concentrated in the posterior distribution, implying a better convergence of the generated samples. It is therefore the most optimal algorithm for the quantification of parameters under uncertainty. Descriptions of the posterior distribution of each dimension are listed below:
\begin{itemize}
    \item TT: The distribution resembles a normal distribution with a peak around $2.8$. The values are clustered around this mean, suggesting a small standard deviation.
    \item C0: The distribution resembles a normal distribution with a sharp peak around $2.1$, with also a high concentration of values near the mean indicating a small standard deviation.
    \item $\beta$ (beta): The distribution is roughly normal with its peak centered around 2.0. The values spread symmetrically from 1.5 to 2.5, indicating moderate variability.
    \item ETF: The distribution has a peak around 0.02 but with more spread, suggesting a normal distribution with a higher standard deviation.
    \item FC: The distribution shows a peak of around 250. It also has a narrow spread, which suggests a small standard deviation
    \item FRAC: The distribution appears to follow a normal distribution centered around 0.2. The spread from 0.15 to 0.25 indicates moderate variability.
    \item K2: The distribution exhibits a peak around 0.048, which is on the upper edge of the complete interval. Values spread narrowly on the left side of the peak.
\end{itemize}


Nevertheless, there is still plenty of work that can be done further regarding the topic of the thesis. For one, the acceptance rate of each algorithm could be further investigated. By tracking the percentage of iterations where the generated samples are accepted, the acceptance rate of the algorithms can be determined, so further improvement regarding sampling efficiency can be investigated and made. For another, the autocorrelation plots of generated samples using algorithms with different effective sample sizes can be examined. Effective sample size is a technique that is used to reduce the correlation between samples that are generated behind each other. The autocorrelation plots can be used to assess this aspect in a visual way, which is not conducted in this thesis. Besides, the DREAM algorithm has the potential to deliver more precise inferred results. Even though the DREAM algorithm performs better than all other algorithms in terms of parameter quantification under uncertainty, the Bayesian inferred result does not exceed the accuracy of the one from the general parallel Metropolis-Hastings algorithm. Further tuning can be made around the parameters so that a more precise inferred result could potentially be derived. Apart from that, the anomaly of the testing data set is not well predicted. Even though we use this aspect to determine the configuration of the time series, on which the Markov chain Monte Carlo algorithms shall sample, the actual result of anomaly prediction is left to be desired. Finding a set of input algorithm parameter configurations and training data sets could be the key to a better result in terms of anomaly prediction. Last but not least, more algorithms of Markov chain Monte Carlo sampling can be tried for the Bayesian inference problem, so that algorithms with potential better performances in terms of the Bayesian inference problem for the hydrological model could be exploited and invented.
